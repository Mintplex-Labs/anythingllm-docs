---
title: "Local Fine-Tuning"
description: "How to use AnythingLLM Local Fine-Tuning"
---

import { Callout } from "nextra/components";
import Image from "next/image";

<Callout type="warning">
  **High performance GPU required**

The process of training your own LLM locally is _very resource intensive_ and will require a GPU with **at least** 16GB of VRAM. If you are under this specification
this process **will not work**.

</Callout>

# How to get started

_Local fine-tuning is currently unavailable and will be available in the [GitHub repo](https://github.com/Mintplex-Labs/anything-llm)_

This documentation will be updated once available.
