---
title: "v1.5.8"
description: "AnythingLLM Desktop v.1.5.8 Changelog"
---

import Image from "next/image";

<Image
  src="/images/product/changelog/header-image.png"
  height={1080}
  width={1920}
  quality={100}
  alt="AnythingLLM Changelog v1.5.8"
/>

## New Features:

- [x] [Automatic document sync beta](/beta-preview/active-features/live-document-sync)
- [x] Experimental Feature support for future features :)
- [x] Automatic Ollama/LMStudio endpoint discovery
- [x] Built-in Ollama bumped to 0.1.47 (w/ automatic NVIDIA and AMD GPU support!)
- [x] You can now specify where you want to install AnythingLLM on Windows
- [x] Rework document picker UI & document picker tooltips
- [x] Support for custom domain confluence URLs
- [x] i18n support for English, Mandarin, Spanish, French, Russian
- [x] Support Claude Sonnet 3.5 model
- [x] Support for searXNG search for agents
- [x] Persist query mode refusal responses as chat history items in DB for record keeping
- [x] Add OpenAI Compatible endpoint support to the API for workspace chatting
- [x] Generic OpenAI embedding provider
- [x] Removed Validation on Azure URLs

## Fixes:

- Patch Linux installer to auto-unpack AppImage for workaround Prisma client limitation
- Bumped LanceDB to new client library for performance improvements
- Really long filenames in rows overflow actions or "Cached" tag
- Fixed issues with built-in Ollama incompatible with some versions of Windows

## What's Next:

- Local file sync for Automatic document sync feature
- Fine-tuning pipeline
- Custom plugins/skills for AnythingLLM app and agents.
