---
title: "Local AI Embedder"
description: "LocalAI is both an LLM engine and supports running embedding models on CPU and GPU"
---

import Image from "next/image";

<Image
  src="/images/anythingllm-setup/embedder-configuration/local/localai/header-image.png"
  height={1080}
  width={1920}
  quality={100}
  alt="Local AI Embedder"
/>

# Local AI Embedder

[LocalAI](https://localai.io) is both an LLM engine **and** supports running embedding models on CPU and GPU. Any HuggingFace model or GGUF embedding model can be used.

This can be configured independently of the LocalAI LLM setting and can be used for both at the same time.

You can update your model to a different model at any time in the **Settings**.

<Image
  src="/images/anythingllm-setup/embedder-configuration/local/localai/localai-embedder.png"
  height={1080}
  width={1920}
  quality={100}
  alt="Local AI Embedder"
/>
