---
title: "Groq LLM"
description: "Groq AI is a model provider popular for pioneering the fastest way to run open-source models."
---

import { Callout } from "nextra/components";
import Image from "next/image";

<Image
  src="/images/anythingllm-setup/llm-configuration/cloud/groq/header-image.png"
  height={1080}
  width={1920}
  quality={100}
  alt="Groq LLM"
/>

# Groq LLM

[Groq](https://groq.com) is a model provider popular for pioneering the fastest way to run open-source models.

This provider enables you to get near-instant replies back from your LLM.

If speed is your primary concern - there is no competition.

## Connecting to Groq

<Callout type="info" emoji="ï¸ðŸ’¡">
  **Valid API Key required!**

    You must obtain a valid API key from [Groq AI](https://wow.groq.com/) for this integration to work.

</Callout>

Like other LLM providers, the Chat Model Selection dropdown will automatically populate when your API key is entered.

All Groq models are currently available for use with AnythingLLM.

You can update your model to a different model at any time in the **Settings**.

<Image
  src="/images/anythingllm-setup/llm-configuration/cloud/groq/groq-llm.png"
  height={1080}
  width={1920}
  quality={100}
  alt="Groq LLM settings"
/>
