---
title: "OpenAI (Generic) LLM"
description: "The Generic OpenAI wrapper is an easy way to interact with any LLM provider that we do not explicitly integrate with and is OpenAi-compatible in both API functionality and inference response."
---

import { Callout } from "nextra/components";
import Image from "next/image";

<Image
  src="/images/anythingllm-setup/llm-configuration/cloud/openai-generic/header-image.png"
  height={1080}
  width={1920}
  quality={100}
  alt="OpenAI (Generic) LLM"
/>

# OpenAI (Generic) LLM

<Callout type="error" emoji="️‼️">
  **Caution!**

    This is a developer-focused llm provider - you should not use it unless you know what you are doing.

</Callout>

The `Generic` OpenAI wrapper is an easy way to interact with any LLM provider that we do not explicitly integrate with and is `OpenAi-compatible` in both API functionality and inference response.

You should only use this provider if you know the LLM provider you wish it interact with is OpenAI compatible and you understand what each input is for.

## Connecting to OpenAI (Generic)

<Callout type="warning" emoji="️⚠️">
  **Use with Caution**

    Generic OpenAI is a highly configurable and as such may not function as intended if you input any configuration setting incorrectly.

</Callout>

You can update your configuration at any time in the **Settings**.

<Image
  src="/images/anythingllm-setup/llm-configuration/cloud/openai-generic/openai-generic-llm.png"
  height={1080}
  width={1920}
  quality={100}
  alt="OpenAI (Generic) LLM settings"
/>
