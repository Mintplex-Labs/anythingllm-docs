---
title: "AnythingLLM Default LLM"
description: "AnythingLLM ships with a built-in LLM engine and provider that enables you to download popular and highly-rated LLMs like LLama-3, Phi-3 and more that can run locally on your CPU and GPU."
---

import { Callout } from "nextra/components";
import Image from "next/image";

<Image
  src="/images/anythingllm-setup/llm-configuration/local/built-in/header-image.png"
  height={1080}
  width={1920}
  quality={100}
  alt="AnythingLLM Default LLM"
/>

# AnythingLLM Default LLM

<Callout type="info" emoji="ï¸ðŸ’¡">
  **DESKTOP ONLY!**

    This default llm provider feature is only present on Desktop Version of AnythingLLM

</Callout>

AnythingLLM ships with a built-in LLM engine and provider that enables you to download popular and highly-rated LLMs like LLama-3, Phi-3 and more that can run locally on your CPU and GPU.

When you boot up AnythingLLM Desktop you will be able to select the model you wish to download. Its progress will be tracked in the top-right of the application window.

You can update your model to a different model at any time in the **Settings**.

<Image
  src="/images/anythingllm-setup/llm-configuration/local/built-in/default-llm.png"
  height={1080}
  width={1920}
  quality={100}
  alt="AnythingLLM Default LLM"
/>
